# 2.  线性回归  

## 2.1 定义

线性回归是一个从输入变量到输出的线性映射，线性回归属于回归任务，输出是一个标量：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210709154939648.png" alt="image-20210709154939648" style="zoom:80%;" />

线性回归模型可以表示为输入变量的线性组合：

​	$f(𝒙, 𝒘)= b + 𝑤_1𝑥_1 + ⋯ + 𝑤_𝑛𝑥_𝑛$

引入输入变量的非线性激活函数$\phi$后，表示为：

​	$f(x,w)=b+\Sigma_{j=1}^{N-1}w_j\phi(x_j)$

为了衡量拟合最好的模型，引入**损失函数**，如平方损失：

​		$J(w)=\frac{1}{2m}\Sigma^{m}_{i=1}l(f_w(x^{i}),y^i)=\frac{1}{2m}\Sigma^{m}_{i=1}(f_w(x^{i})-y^i)^2$

我们的目标是是损失函数最小化：

​	$min_wJ(w)$

通常我们使用**梯度下降法**令损失函向最大梯度的反方向移动，以此达到局部最小值：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210709173337304.png" alt="image-20210709173337304" style="zoom:80%;" />

对于平方损失，重复更新权重w，损失将一步一步下降，直到达到局部最小值：

​	$w_i = w_i-\eta \Sigma_n-(y^n-f_w(x^n))x_i^n$

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210709174139203.png" alt="image-20210709174139203" style="zoom:60%;" />